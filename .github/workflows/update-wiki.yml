name: Publish CCTV Timelapse Software Docs To Wiki

on:
  schedule:
    # Sunday 21:30 UTC = Monday 01:00 Iran
    - cron: "30 23 * * 0"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout main repo
        uses: actions/checkout@v4
        with:
          path: main-repo

      - name: Clone target Wiki
        run: |
          git clone https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/intellsoft/time-lapse-software-with-cctv-playback-film.wiki.git wiki

      - name: Fetch source documentation page
        run: |
          curl -L "https://intellsoft.ir/docs/%d8%b1%d8%a7%d9%87%d9%86%d9%85%d8%a7%db%8c-%d9%86%d8%b1%d9%85-%d8%a7%d9%81%d8%b2%d8%a7%d8%b1-%d8%aa%d8%a8%d8%af%db%8c%d9%84-%d9%81%db%8c%d9%84%d9%85-%d8%af%d9%88%d8%b1%d8%a8%db%8c%d9%86-%d9%85%d8%af/" -o web-docs.html

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install beautifulsoup4

      - name: Extract documentation sections (Web + README)
        run: |
          mkdir -p articles
          python3 - <<PYTHON
          import os
          from bs4 import BeautifulSoup

          articles_data = []

          # ============ Ø¨Ø®Ø´ Û±: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² README Ø±ÛŒÙ¾Ø§Ø²ÛŒØªÙˆØ±ÛŒ ============
          readme_path = "main-repo/README.md"
          if os.path.exists(readme_path):
              with open(readme_path, "r", encoding="utf-8") as f:
                  readme_content = f.read()
              
              # ØªÙ‚Ø³ÛŒÙ… README Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ø³Ø·Ø­ Û² (##)
              sections = readme_content.split("\n## ")
              for section in sections[1:]:  # Ø¨Ø®Ø´ Ø§ÙˆÙ„ Ù…Ù‚Ø¯Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ù‡Ø¯Ø± Ø§Ø³Øª
                  lines = section.split("\n")
                  title = lines[0].strip()
                  content = "\n".join(lines[1:]).strip()
                  
                  # Ø­Ø°Ù Ø¨Ø®Ø´ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¯Ø± Ø§Ù†ØªÙ‡Ø§
                  if title in ["About", "Resources", "Releases", "Packages"]:
                      continue
                  
                  # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø·ÙˆÙ„ Ø¹Ù†ÙˆØ§Ù† Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù… ÙØ§ÛŒÙ„
                  slug = title.replace(" ", "-").replace(":", "").replace("/", "-")
                  slug = "".join(c for c in slug if c.isalnum() or c == "-")[:40].strip("-")
                  
                  articles_data.append((slug, title, content, "readme"))
          
          # ============ Ø¨Ø®Ø´ Û²: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² ØµÙØ­Ù‡ ÙˆØ¨ ============
          with open("web-docs.html", encoding="utf-8") as f:
              soup = BeautifulSoup(f, "html.parser")
          
          # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ù†Ø§ÙˆÛŒÙ† Ø§ØµÙ„ÛŒ Ø§Ø² ØµÙØ­Ù‡ Ø±Ø§Ù‡Ù†Ù…Ø§ (Ù„ÛŒØ³Øª Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ù…Ø­ØªÙˆØ§ÛŒ ØµÙØ­Ù‡)
          content_div = soup.find("div", class_="entry-content") or soup.find("article")
          if content_div:
              for p in content_div.find_all("p"):
                  text = p.get_text(strip=True)
                  # Ø¹Ù†Ø§ÙˆÛŒÙ† ÙØ§Ø±Ø³ÛŒ Ú©Ù‡ Ø¯Ø± Ù…Ø­ØªÙˆØ§ÛŒ ØµÙØ­Ù‡ Ù‡Ø³ØªÙ†Ø¯
                  keywords = ["Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒÙ‡Ø§ÛŒ", "Ø´Ø±ÙˆØ¹ Ú©Ø§Ø±", "Ø§ØªØµØ§Ù„ Ø¨Ù‡ NVR", "Ø´Ø¨Ú©Ù‡ Ù…Ø­Ù„ÛŒ", "Ø¢ÛŒÙ¾ÛŒ Ø§Ø³ØªØ§ØªÛŒÚ©"]
                  if any(kw in text for kw in keywords) and len(text) < 100:
                      title = text
                      slug = title.replace(" ", "-").replace(":", "")
                      slug = "".join(c for c in slug if c.isalnum() or c == "-")[:40].strip("-")
                      
                      # Ø§Ú¯Ø± Ø§ÛŒÙ† Ø¹Ù†ÙˆØ§Ù† Ù‚Ø¨Ù„Ø§Ù‹ Ø§Ø² README Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø´Ø¯Ù‡ØŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
                      if not any(title in t for _, t, _, _ in articles_data):
                          articles_data.append((slug, title, f"Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø§Ø² Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø±Ø³Ù…ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø³Øª: [{title}](https://intellsoft.ir/docs/Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ-Ù†Ø±Ù…-Ø§ÙØ²Ø§Ø±-ØªØ¨Ø¯ÛŒÙ„-ÙÛŒÙ„Ù…-Ø¯ÙˆØ±Ø¨ÛŒÙ†-Ù…Ø¯/)", "web"))

          # ============ Ù†ÙˆØ´ØªÙ† ÙØ§ÛŒÙ„ Ù„ÛŒØ³Øª Ù†Ù‡Ø§ÛŒÛŒ ============
          with open("articles/list.txt", "w", encoding="utf-8") as out:
              for slug, title, content, src in articles_data:
                  # Ø°Ø®ÛŒØ±Ù‡ Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø§Ø² Ù…Ø­ØªÙˆØ§ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´
                  preview = content[:300].replace("\n", " ") + "..."
                  out.write(f"{slug}\t{title}\t{preview}\t{src}\n")
          PYTHON

      - name: Generate detailed Wiki pages
        run: |
          while IFS=$'\t' read -r slug title preview src; do
            file="wiki/$slug.md"
            
            # Ø§Ú¯Ø± ØµÙØ­Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ Ùˆ Ø§Ø² README Ø§Ø³ØªØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú©Ø±Ø¯ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
            # Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ú¯ÛŒØŒ ÙÙ‚Ø· ØµÙØ­Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø³Ø§Ø®ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
            if [ -f "$file" ]; then
              echo "Wiki page already exists: $title"
              continue
            fi
            
            echo "Creating Wiki page: $title"
            
            # Ø³Ø§Ø®Øª ØµÙØ­Ù‡ ÙˆÛŒÚ©ÛŒ
            {
              echo "# $title"
              echo ""
              
              if [ "$src" = "readme" ]; then
                echo "ðŸ“¥ **Ù…Ù†Ø¨Ø¹:** Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø³Ù…ÛŒ Ø±ÛŒÙ¾Ø§Ø²ÛŒØªÙˆØ±ÛŒ"
              else
                echo "ðŸŒ **Ù…Ù†Ø¨Ø¹:** Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ÙˆØ¨Ø³Ø§ÛŒØª"
              fi
              
              echo ""
              echo "---"
              echo ""
              
              # Ø¨Ø±Ø§ÛŒ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ READMEØŒ Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù…Ù„ Ø±Ø§ Ø§Ø² ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†ÛŒÙ…
              if [ "$src" = "readme" ]; then
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø®Ø´ Ú©Ø§Ù…Ù„ Ø§Ø² README (Ø§ÛŒÙ†Ø¬Ø§ Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡)
                echo "$preview" | sed 's/\.\.\.$//'
                echo ""
                echo "> â„¹ï¸ Ø¨Ø±Ø§ÛŒ Ù…Ø·Ø§Ù„Ø¹Ù‡ Ú©Ø§Ù…Ù„ Ø§ÛŒÙ† Ø¨Ø®Ø´ØŒ Ø¨Ù‡ [README Ø§ØµÙ„ÛŒ](https://github.com/intellsoft/time-lapse-software-with-cctv-playback-film#readme) Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯."
              else
                echo "$preview"
                echo ""
                echo "ðŸ‘‰ **[Ù…Ø´Ø§Ù‡Ø¯Ù‡ ØµÙØ­Ù‡ Ú©Ø§Ù…Ù„ Ø±Ø§Ù‡Ù†Ù…Ø§]($(echo "https://intellsoft.ir/docs/Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ-Ù†Ø±Ù…-Ø§ÙØ²Ø§Ø±-ØªØ¨Ø¯ÛŒÙ„-ÙÛŒÙ„Ù…-Ø¯ÙˆØ±Ø¨ÛŒÙ†-Ù…Ø¯/" | sed 's/ /%20/g'))**"
              fi
              
              echo ""
              echo "---"
              echo ""
              echo "ðŸ”„ Ø§ÛŒÙ† ØµÙØ­Ù‡ Ø¨Ù‡â€ŒØ·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± ØªÙˆØ³Ø· GitHub Actions Ø§Ø² Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø± **CCTV Timelapse Playback** Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯."
              echo ""
              echo "ðŸ“Œ **ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡:** Ø¹Ù„ÛŒ Ø¹Ø¨Ø§Ø³â€ŒÙ¾ÙˆØ±"
              
            } > "$file"
            
          done < articles/list.txt

      - name: Commit and push to Wiki
        run: |
          cd wiki
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git add .
          git commit -m "Auto sync CCTV Timelapse Software documentation to Wiki" || exit 0
          git push
